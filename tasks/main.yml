
# - name: Defining some env. variables (PSNODES)
#   lineinfile: dest=/etc/environment line=PSNODES={{ num_ps_nodes }} create=yes

# - name: Defining some env. variables (MNODES)
#   lineinfile: dest=/etc/environment line=MNODES={{ num_master_nodes }} create=yes

# - name: Defining some env. variables (WNODES)
#   lineinfile: dest=/etc/environment line=WNODES={{ num_worker_nodes }} create=yes

- name: Install Jupyter Notebook,Matplotlib and boto3
  pip: 
   name: "{{ item }}" 
   executable: pip3 
  with_items:
    - jupyter
    - matplotlib
    - boto3

- name: Copying Uploading Script
  template: src=s3uploading.py.j2 dest=/tmp/s3uploading.py

#  Already done...
# - name: Cloning repository with TF code 
#   git: 
#     repo: 'https://github.com/JJorgeDSIC/DistributedTensorFlowCodeForIM.git'
#     dest: '{{ clone_path }}'
#     clone: yes
#   become: yes
#   become_user: ubuntu  

# ####################################################
# #  --------- Configuration ----------------------  #
# ####################################################
# - name: Install Tensorflow
#   pip:
#     name: tensorflow
#     executable: pip3 
#   when: num_gpu == 0

# ####################################################
# #  --------- Configuration ----------------------  #
# ####################################################
# - name: Install Tensorflow (GPU)
#   pip:
#     name: tensorflow-gpu
#     executable: pip3 
#   when: num_gpu > 0

- name: Launch tensorboard
  command: ./launch_tensorboard.sh {{ model_path }}
  when: launch_tensorboard
  become: yes
  become_user: ubuntu  
  args:
    chdir: '{{ clone_path }}/{{ work_dir }}'

- name: Training (PS)
  command: ./launch_training_dist_async.sh {{ num_gpu }} {{ data_path }} {{ model_path }} {{ train_steps }} ps {{ ps_nodes_list }} {{ worker_nodes_list }}
  when: node_type == "ps" and launch_training
  become: yes
  become_user: ubuntu  
  async: 432000
  poll: 0
  args:
    chdir: '{{ clone_path }}/{{ work_dir }}'

- name: Training (MASTER)
  command: ./launch_training_dist_async.sh {{ num_gpu }} {{ data_path }} {{ model_path }} {{ train_steps }} worker {{ ps_nodes_list }} {{ worker_nodes_list }}
  when: node_type == "master" and launch_training
  become: yes
  become_user: ubuntu  
  async: 432000
  poll: 0 
  register: training_finished
  args:
    chdir: '{{ clone_path }}/{{ work_dir }}'

- name: Training (WORKER)
  command: ./launch_training_dist_async.sh {{ num_gpu }} {{ data_path }} {{ model_path }} {{ train_steps }} worker {{ ps_nodes_list }} {{ worker_nodes_list }}
  when: node_type == "worker" and launch_training
  become: yes
  become_user: ubuntu  
  async: 432000
  poll: 0
  args:
    chdir: '{{ clone_path }}/{{ work_dir }}'

- name: 'Check on async task'
  async_status:
    jid: "{{ training_finished.ansible_job_id }}"
  register: job_result
  when: node_type == "master"
  become: yes
  become_user: ubuntu 
  until: job_result.finished
  retries: 1000

- name: 'Copy model locally'
  command: /opt/hadoop/bin/hadoop fs -get /cifar-10-model/ /tmp/cifar-10-model
  become: yes
  become_user: ubuntu  
  register: upload_model
  when: job_result is succeeded and node_type == "master"

- name: 'Uploading model'
  command: python3 s3uploading.py
  when:  upload_model is succeeded and node_type == "master"
  become: yes
  become_user: ubuntu  
  args:
    chdir: '/tmp/'


# - name: 'Uploading model'
#   aws_s3:
#     aws_access_key: '{{ access_key }}'
#     aws_secret_key: '{{ secret_key }}'
#     bucket: alucloud143
#     object: /cifar-10-model-cpu-gpu
#     src: /tmp/cifar-10-model/checkpoint
#     mode: put
#   when: upload_model is succeeded and node_type == "master"

# - name: basic upload
#   s3_sync:
#     aws_access_key: '{{ access_key }}'
#     aws_secret_key: '{{ secret_key }}'
#     bucket: alucloud143
#     file_root: /tmp/cifar-10-model/
#   when: upload_model is succeeded and node_type == "master"
